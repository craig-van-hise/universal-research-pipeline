@article{Lentz2007Virtual,
  title = {Virtual Reality System with Integrated Sound Field Simulation and Reproduction},
  author = {Tobias Lentz and Dirk Schröder and Michael Vorländer and Ingo Assenmacher},
  year = {2007},
  journal = {OpenAlex},
  doi = {10.1155/2007/70540},
  url = {https://asp-eurasipjournals.springeropen.com/counter/pdf/10.1155/2007/70540},
  abstract = {A real-time audio rendering system is introduced which combines a full room-specific simulation, dynamic crosstalk cancellation, and multitrack binaural synthesis for virtual acoustical imaging. The system is applicable for any room shape (normal, long, flat, coupled), independent of the a priori assumption of a diffuse sound field. This provides the possibility of simulating indoor or outdoor spatially distributed, freely movable sources and a moving listener in virtual environments. In addition to that, near-to-head sources can be simulated by using measured near-field HRTFs. The reproduction component consists of a headphone-free reproduction by dynamic crosstalk cancellation. The focus of the project is mainly on the integration and interaction of all involved subsystems. It is demonstrated that the system is capable of real-time room simulation and reproduction and, thus, can be used as a reliable platform for further research on VR applications.}
}

@article{Coleman2014Acoustic,
  title = {Acoustic contrast, planarity and robustness of sound zone methods using a circular loudspeaker array},
  author = {Peter John Cusack Coleman and Philip J. B. Jackson and Marek Olik and Martin Bo Møller and Martin Olsen and Jan Abildgaard Pedersen},
  year = {2014},
  journal = {OpenAlex},
  doi = {10.1121/1.4866442},
  url = {https://pdfs.semanticscholar.org/30e5/4f0f268e910d4c01baf1b2b9607576b0ad97.pdf},
  abstract = {Since the mid 1990s, acoustics research has been undertaken relating to the sound zone problem—using loudspeakers to deliver a region of high sound pressure while simultaneously creating an area where the sound is suppressed—in order to facilitate independent listening within the same acoustic enclosure. The published solutions to the sound zone problem are derived from areas such as wave field synthesis and beamforming. However, the properties of such methods differ and performance tends to be compared against similar approaches. In this study, the suitability of energy focusing, energy cancelation, and synthesis approaches for sound zone reproduction is investigated. Anechoic simulations based on two zones surrounded by a circular array show each of the methods to have a characteristic performance, quantified in terms of acoustic contrast, array control effort and target sound field planarity. Regularization is shown to have a significant effect on the array effort and achieved acoustic contrast, particularly when mismatched conditions are considered between calculation of the source weights and their application to the system.}
}

@article{Hong2017Spatial,
  title = {Spatial Audio for Soundscape Design: Recording and Reproduction},
  author = {Joo Young Hong and Jianjun He and Bhan Lam and Rishabh Gupta and Woon‐Seng Gan},
  year = {2017},
  journal = {OpenAlex},
  doi = {10.3390/app7060627},
  url = {https://www.mdpi.com/2076-3417/7/6/627/pdf?version=1497700319},
  abstract = {With the advancement of spatial audio technologies, in both recording and reproduction, we are seeing more applications that incorporate 3D sound to create an immersive aural experience. Soundscape design and evaluation for urban planning can now tap into the extensive spatial audio tools for sound capture and 3D sound rendering over headphones and speaker arrays. In this paper, we outline a list of available state-of-the-art spatial audio recording techniques and devices, spatial audio physical and perceptual reproduction techniques, emerging spatial audio techniques for virtual and augmented reality, followed by a discussion on the degree of perceptual accuracy of recording and reproduction techniques in representing the acoustic environment.}
}

@article{Lawrence2021Project,
  title = {Project starline},
  author = {Jason Lawrence and Danb Goldman and Supreeth Achar and Gregory Major Blascovich and Joseph G. Desloge and Tommy Fortes and Eric M. Gomez and Sascha Häberling and Hugues Hoppe and Andy Huibers and Claude Knaus and Brian Kuschak and Ricardo Martin-Brualla and Harris Nover and Andrew Ian Russell and Steven M. Seitz and Kevin Tong},
  year = {2021},
  journal = {OpenAlex},
  doi = {10.1145/3478513.3480490},
  url = {https://hhoppe.com/starline.pdf},
  abstract = {We present a real-time bidirectional communication system that lets two people, separated by distance, experience a face-to-face conversation as if they were copresent. It is the first telepresence system that is demonstrably better than 2D videoconferencing, as measured using participant ratings (e.g., presence, attentiveness, reaction-gauging, engagement), meeting recall, and observed nonverbal behaviors (e.g., head nods, eyebrow movements). This milestone is reached by maximizing audiovisual fidelity and the sense of copresence in all design elements, including physical layout, lighting, face tracking, multi-view capture, microphone array, multi-stream compression, loudspeaker output, and lenticular display. Our system achieves key 3D audiovisual cues (stereopsis, motion parallax, and spatialized audio) and enables the full range of communication cues (eye contact, hand gestures, and body language), yet does not require special glasses or body-worn microphones/headphones. The system consists of a head-tracked autostereoscopic display, high-resolution 3D capture and rendering subsystems, and network transmission using compressed color and depth video streams. Other contributions include a novel image-based geometry fusion algorithm, free-space dereverberation, and talker localization.}
}

@article{Shirley2015Clean,
  title = {Clean Audio for TV broadcast: An Object-Based Approach for Hearing-Impaired Viewers},
  author = {Ben Shirley and Rob Oldfield},
  year = {2015},
  journal = {OpenAlex},
  doi = {10.17743/jaes.2015.0017},
  url = {http://downloads.bbc.co.uk/rd/pubs/whp/whp-pdf-files/WHP324.pdf},
  abstract = {As the percentage of the population with hearing loss increases, broadcasters are receiving more complaints about the difficulty in understanding dialog in the presence of background sound and music. This article explores these issues, reviews previously proposed solutions, and presents an object-based approach that can be implemented within MPEG-H to give listeners control of their audio mix. An object-based approach to clean audio, combined with methods to isolate sounds that are important to the narrative and meaning of a broadcast has the potential to enable users to have complete control of the relative levels of all aspects of audio from TV broadcast. This approach was demonstrated at the University of Salford campus in 2013.}
}

@article{Majdak2022Spatially,
  title = {Spatially Oriented Format for Acoustics 2.1: Introduction and Recent Advances},
  author = {Piotr Majdak and Franz Zotter and Fabian Brinkmann and Julien De Muynke and Michael Mihocic and Markus Noisternig},
  year = {2022},
  journal = {OpenAlex},
  doi = {10.17743/jaes.2022.0026},
  url = {https://dael.euracoustics.org/confs/fa2023/data/articles/000729.pdf},
  abstract = {Spatially oriented acoustic data can range from a simple set of impulse responses, such as head-related transfer functions, to a large set of multiple-input multiple-output spatial room impulse responses obtained in complex measurements with a microphone array excited by a loudspeaker array at various conditions. The spatially oriented format for acoustics (SOFA), which was standardized by AES Standard 69, provides a format to store and share such data. SOFA takes into account geometric representations of many acoustic scenarios, data compression, network transfer, and a link to complex room geometries and aims at simplifying the development of interfaces for many programming languages. With the recent advancement of SOFA, the format offers new continuous-direction representation of data by means of spherical harmonics and novel conventions representing many measurement scenarios, such as source directivity and multiple-input multiple-output spatial room impulse responses. This article reviews SOFA by first providing an introduction to SOFA and then describing examples that demonstrate the most recent features of the SOFA 2.1 (AES Standard 69-2022).}
}

@article{Bai2017Solution,
  title = {Solution Strategies for Linear Inverse Problems in Spatial Audio Signal Processing},
  author = {Mingsian R. Bai and Chun Hui Chung and Po-Chen Wu and Yi-Hao Chiang and Chun-May Yang},
  year = {2017},
  journal = {OpenAlex},
  doi = {10.3390/app7060582},
  url = {https://www.mdpi.com/2076-3417/7/6/582/pdf?version=1496711486},
  abstract = {The aim of this study was to compare algorithms for solving inverse problems generally encountered in spatial audio signal processing. Tikhonov regularization is typically utilized to solve overdetermined linear systems in which the regularization parameter is selected by the golden section search (GSS) algorithm. For underdetermined problems with sparse solutions, several iterative compressive sampling (CS) methods are suggested as alternatives to traditional convex optimization (CVX) methods that are computationally expensive. The focal underdetermined system solver (FOCUSS), the steepest descent (SD) method, Newton’s (NT) method, and the conjugate gradient (CG) method were developed to solve CS problems more efficiently in this study. These algorithms were compared in terms of problems, including source localization and separation, noise source identification, and analysis and synthesis of sound fields, by using a uniform linear array (ULA), a uniform circular array (UCA), and a random array. The derived results are discussed herein and guidelines for the application of these algorithms are summarized.}
}

@article{Brinkmann2023Recent,
  title = {Recent Advances in an Open Software for Numerical HRTF Calculation},
  author = {Fabian Brinkmann and W. Kreuzer and Jeffrey Thomsen and Sergejs Dombrovskis and Katharina Pollack and Stefan Weinzierl and Piotr Majdak},
  year = {2023},
  journal = {OpenAlex},
  doi = {10.17743/jaes.2022.0078},
  url = {https://projects.ari.oeaw.ac.at/research/Publications/Articles/2023/Brinkmann_et_al_2023_Mesh2HRTF.pdf},
  abstract = {Mesh2HRTF 1.x is an open-source and fully scriptable end-to-end pipeline for the numerical calculation of head-related transfer functions (HRTFs). The calculations are based on 3D meshes of listener’s body parts such as the head, pinna, and torso. The numerical core of Mesh2HRTF is written in C++ and employs the boundary-element method for solving the Helmholtz equation. It is accelerated by a multilevel fast multipole method and can easily be parallelized to further speed up the computations. The recently refactored framework of Mesh2HRTF 1.x contains tools for preparing the meshes as well as specific post-processing and inspection of the calculatedHRTFs. The resultingHRTFs are saved in the spatially oriented format for acoustics being directly applicable in virtual and augmented reality applications and psychoacoustic research. The Mesh2HRTF 1.x code is automatically tested to assure high quality and reliability. A comprehensive online documentation enables easy access for users without in-depth knowledge of acoustic simulations.}
}

@article{Neidhardt2021The,
  title = {The Availability of a Hidden Real Reference Affects the Plausibility of Position-Dynamic Auditory AR},
  author = {Annika Neidhardt and Anna Maria Zerlik},
  year = {2021},
  journal = {OpenAlex},
  doi = {10.3389/frvir.2021.678875},
  url = {https://www.frontiersin.org/articles/10.3389/frvir.2021.678875/pdf},
  abstract = {This study examines the plausibility of Auditory Augmented Reality (AAR) realized with position-dynamic binaural synthesis over headphones. An established method to evaluate the plausibility of AAR asks participants to decide whether they are listening to the virtual or real version of the sound object. To date, this method has only been used to evaluate AAR systems for seated listeners. The AAR realization examined in this study instead allows listeners to turn to arbitrary directions and walk towards, past, and away from a real loudspeaker that reproduced sound only virtually. The experiment was conducted in two parts. In the first part, the subjects were asked whether they are listening to the real or the virtual version, not knowing that it was always the virtual version. In the second part, the real versions of the scenes where the loudspeaker actually reproduced sound were added. Two different source positions, three different test stimuli, and two different sound levels were considered. Seventeen volunteers, including five experts, participated. In the first part, none of the participants noticed that the virtual reproduction was active throughout the different test scenes. The inexperienced listeners tended to accept the virtual reproduction as real, while experts distributed their answers approximately equally. In the second part, experts could identify the virtual version quite reliably. For inexperienced listeners, the individual results varied enormously. Since the presence of the headphones influences the perception of the real sound field, this shadowing effect had to be considered in the creation of the virtual sound source as well. This requirement still limits test methods considering the real version in its ecological validity. Although the results indicate that the availability of a hidden real reference leads to a more critical evaluation, it is crucial to be aware that the presence of the headphones slightly distorts the reference. This issue seems more vital to the plausibility estimates achieved with this evaluation method than the increased freedom in motion.}
}

@article{Otani2020Binaural,
  title = {Binaural Ambisonics: Its optimization and applications for auralization},
  author = {Makoto Otani and Haruki Shigetani and Masataka Mitsuishi and Ryo Matsuda},
  year = {2020},
  journal = {OpenAlex},
  doi = {10.1250/ast.41.142},
  url = {https://www.jstage.jst.go.jp/article/ast/41/1/41_E19229/_pdf},
  abstract = {To better understand acoustic environment and the resulting auditory perception, it is essential to capture, analyze, and reproduce a sound field as a three-dimensional physical phenomenon because spatial aspects of auditory perception play important roles in various situations in our lives. Some approaches have been proposed to achieve the three-dimensional capture and reproduction of acoustic fields. Among them, Higher-Order Ambisonics (HOA) based on spherical harmonics expansion enables the capture and reproduction of a directivity pattern of incoming sound waves. On the basis of HOA, three-dimensional auditory space can be presented to a listener typically via a spherical loudspeaker array. In addition, binaural synthesis emulating the loudspeaker presentation enables HOA reproduction with a set of headphones or several loudspeakers by employing crosstalk cancellation. Thus, we are developing an HOA-based binaural reproduction/auralization system with head tracking. This system is aimed at realizing the reproduction and auralization of a sound field, including one excited by the listener's own voice. In this paper, we review the topics related to the reproduction and auralization of the sound field and introduce the HOA-based binaural synthesis system we have developed, as well as our works on sweet-spot expansion in HOA decoding and self-voice reproduction/auralization.}
}

